{
 "metadata": {
  "name": "",
  "signature": "sha256:8a2c8ba7ea466cc9c0721d3d8da79d784dd453750334da86dc03395cbf7f7b2a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#A = AWS_keypair_management()\n",
      "#(Creds,bad_files) = A.Get_Working_Credentials('/home/ubuntu/Vault')\n",
      "#pair = Creds['nima']['Creds'][0]\n",
      "#key_id = pair['Access_Key_Id']\n",
      "#secret_key = pair['Secret_Access_Key']\n",
      "#job_flow_id = find_waiting_flow(key_id,secret_key)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            if elements[0]=='station':\n",
      "                out=('header',1)\n",
      "            else:\n",
      "                out=(elements[1],1)\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            out=('error',1)\n",
      "\n",
      "        finally:\n",
      "            yield out\n",
      "            \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather.py\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running job inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!ls -l $local_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 19 22:40 /home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_weather.py $local_data > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_weather.ubuntu.20140521.004828.939699\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140521.004828.939699/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 21\r\n",
        "    mapper-all: 999\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140521.004828.939699/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_weather.ubuntu.20140521.004828.939699/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140521.004828.939699/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 21\r\n",
        "    mapper-all: 999\r\n",
        "    reducer: 21\r\n",
        "Moving /tmp/mr_weather.ubuntu.20140521.004828.939699/step-0-reducer_part-00000 -> /tmp/mr_weather.ubuntu.20140521.004828.939699/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_weather.ubuntu.20140521.004828.939699/output\r\n",
        "removing tmp directory /tmp/mr_weather.ubuntu.20140521.004828.939699\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"DAPR\"\t29\r\n",
        "\"DASF\"\t3\r\n",
        "\"DWPR\"\t17\r\n",
        "\"MDPR\"\t37\r\n",
        "\"MDSF\"\t5\r\n",
        "\"PRCP\"\t420\r\n",
        "\"SNOW\"\t83\r\n",
        "\"SNWD\"\t85\r\n",
        "\"TMAX\"\t123\r\n",
        "\"TMIN\"\t106\r\n",
        "\"TOBS\"\t45\r\n",
        "\"WT01\"\t12\r\n",
        "\"WT03\"\t7\r\n",
        "\"WT04\"\t5\r\n",
        "\"WT05\"\t2\r\n",
        "\"WT06\"\t3\r\n",
        "\"WT08\"\t2\r\n",
        "\"WT11\"\t3\r\n",
        "\"WT14\"\t4\r\n",
        "\"WT16\"\t5\r\n",
        "\"WT18\"\t3\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## managing AWS Credentials ##\n",
      "The full details on how to get the credentials set up is given here: https://docs.google.com/document/d/1xDUy4ZI2yr1eCCRQ4ynWHsctbEb7ySHrSynBu0bxupU/edit?usp=sharing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "nima AKIAJ7YQZ7V7CO53WP5A\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Checking for an available job flow###\n",
      "Before submitting your job for execution you need to find out which job flows are active and waiting. THe following cell will do that for you. If there is a waiting cluster, it will put it's ID into the variable `job_flow_id`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setting up the mrjob configuration file ###\n",
      "The last step before submitting the job is to insert the credentials into the file `/home/ubuntu/UCSD_BigData/utils/mrjob.conf.template` and put the result in the default location for the mrjob configuration file which is: `/home/ubuntu/.mrjob.conf`\n",
      "this is done by the following line. If the return value is `True` you are good to go. If it is `False` something went wrong and you should get an error message.\n",
      "\n",
      "The template file should work as is. However, feel free to change and add fields to this configuration file to make it your own.\n",
      "\n",
      "This step needs to be done just one time. Redone only when starting a new EC2 instance or if the credentials changed.\n",
      "It is better to do it in an interactive shell, rather than in a notebook. Here it is done in the notebook for demonstration purpose."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /home/ubuntu/UCSD_BigData/utils/\n",
      "!python Make.mrjob.conf.py\n",
      "%cd ../notebooks/weather.mapreduce/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/utils\n",
        "Created the configuration file: /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assuming the steps up to here were all successful, you should be ready to launch your mrjob job. There is no need to change anything\n",
      "in the following line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_weather.py -r emr --emr-job-flow-id  $job_flow_id < $local_data > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-c858690d1c726bea\r\n",
        "using s3://mrjob-c858690d1c726bea/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather.ubuntu.20140520.214506.526538\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading from STDIN\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating S3 bucket 'mrjob-c858690d1c726bea' to use as scratch space\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-c858690d1c726bea/tmp/mr_weather.ubuntu.20140520.214506.526538/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-1RE8D7HBISOI0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.3s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214506.526538: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 60.7s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214506.526538: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 91.1s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214506.526538: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 69.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-1RE8D7HBISOI0\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://mrjob-c858690d1c726bea/tmp/mr_weather.ubuntu.20140520.214506.526538/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather.ubuntu.20140520.214506.526538\r\n",
        "Removing all files in s3://mrjob-c858690d1c726bea/tmp/mr_weather.ubuntu.20140520.214506.526538/\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_weather.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-0f34895088c188fb\r\n",
        "using s3://mrjob-0f34895088c188fb/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather.ubuntu.20140520.214718.553161\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating S3 bucket 'mrjob-0f34895088c188fb' to use as scratch space\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-0f34895088c188fb/tmp/mr_weather.ubuntu.20140520.214718.553161/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-1RE8D7HBISOI0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 60.8s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214718.553161: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 91.2s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214718.553161: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 121.5s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214718.553161: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 152.6s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214718.553161: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 183.0s ago, status RUNNING: Running step (mr_weather.ubuntu.20140520.214718.553161: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 135.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  File Input Format Counters :\r\n",
        "    Bytes Read: 7670788923\r\n",
        "  File Output Format Counters :\r\n",
        "    Bytes Written: 1540\r\n",
        "  FileSystemCounters:\r\n",
        "    FILE_BYTES_READ: 25157\r\n",
        "    FILE_BYTES_WRITTEN: 1976920\r\n",
        "    HDFS_BYTES_READ: 7670794863\r\n",
        "    S3_BYTES_WRITTEN: 1540\r\n",
        "  Job Counters :\r\n",
        "    Data-local map tasks: 58\r\n",
        "    Launched map tasks: 61\r\n",
        "    Launched reduce tasks: 12\r\n",
        "    Rack-local map tasks: 3\r\n",
        "    SLOTS_MILLIS_MAPS: 2502234\r\n",
        "    SLOTS_MILLIS_REDUCES: 297186\r\n",
        "    Total time spent by all maps waiting after reserving slots (ms): 0\r\n",
        "    Total time spent by all reduces waiting after reserving slots (ms): 0\r\n",
        "  Map-Reduce Framework:\r\n",
        "    CPU time spent (ms): 1198090\r\n",
        "    Combine input records: 9358395\r\n",
        "    Combine output records: 5079\r\n",
        "    Map input bytes: 7668890105\r\n",
        "    Map input records: 9358395\r\n",
        "    Map output bytes: 84225557\r\n",
        "    Map output materialized bytes: 68465\r\n",
        "    Map output records: 9358395\r\n",
        "    Physical memory (bytes) snapshot: 28884373504\r\n",
        "    Reduce input groups: 134\r\n",
        "    Reduce input records: 5079\r\n",
        "    Reduce output records: 134\r\n",
        "    Reduce shuffle bytes: 68465\r\n",
        "    SPLIT_RAW_BYTES: 5940\r\n",
        "    Spilled Records: 10158\r\n",
        "    Total committed heap usage (bytes): 27202158592\r\n",
        "    Virtual memory (bytes) snapshot: 126552592384\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 9358395\r\n",
        "    reducer: 134\r\n",
        "Streaming final output from s3://mrjob-0f34895088c188fb/tmp/mr_weather.ubuntu.20140520.214718.553161/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather.ubuntu.20140520.214718.553161\r\n",
        "Removing all files in s3://mrjob-0f34895088c188fb/tmp/mr_weather.ubuntu.20140520.214718.553161/\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"DATX\"\t6001\r\n",
        "\"FRGT\"\t282\r\n",
        "\"MDPR\"\t349252\r\n",
        "\"MDTN\"\t6162\r\n",
        "\"MXPN\"\t13698\r\n",
        "\"SN31\"\t357\r\n",
        "\"SN53\"\t125\r\n",
        "\"SX15\"\t2\r\n",
        "\"SX51\"\t108\r\n",
        "\"WDF2\"\t13658\r\n",
        "\"WESF\"\t31503\r\n",
        "\"WT04\"\t163690\r\n",
        "\"WT15\"\t4392\r\n",
        "\"ACMC\"\t13\r\n",
        "\"DASF\"\t17195\r\n",
        "\"EVAP\"\t24827\r\n",
        "\"FMTM\"\t13372\r\n",
        "\"FRTH\"\t135\r\n",
        "\"MDEV\"\t10851\r\n",
        "\"PGTM\"\t26220\r\n",
        "\"SN52\"\t936\r\n",
        "\"SNWD\"\t864192\r\n",
        "\"SX03\"\t752\r\n",
        "\"SX14\"\t3\r\n",
        "\"SX36\"\t7\r\n",
        "\"SX61\"\t23\r\n",
        "\"SX72\"\t9\r\n",
        "\"SX83\"\t9\r\n",
        "\"TMAX\"\t967931\r\n",
        "\"TSUN\"\t10557\r\n",
        "\"WDF1\"\t5319\r\n",
        "\"WDFI\"\t72\r\n",
        "\"WSF2\"\t13657\r\n",
        "\"WT03\"\t272406\r\n",
        "\"WT14\"\t38369\r\n",
        "\"WV01\"\t397\r\n",
        "\"ACSH\"\t9172\r\n",
        "\"DAPR\"\t299139\r\n",
        "\"DATN\"\t6162\r\n",
        "\"FRGB\"\t113\r\n",
        "\"MNPN\"\t13664\r\n",
        "\"PRCP\"\t2521007\r\n",
        "\"SN51\"\t108\r\n",
        "\"SX02\"\t3373\r\n",
        "\"SX13\"\t60\r\n",
        "\"SX35\"\t22\r\n",
        "\"SX82\"\t9\r\n",
        "\"WESD\"\t55740\r\n",
        "\"WSF1\"\t5344\r\n",
        "\"WSFI\"\t77\r\n",
        "\"WT02\"\t22199\r\n",
        "\"WT13\"\t7208\r\n",
        "\"DAEV\"\t10849\r\n",
        "\"GAHT\"\t936\r\n",
        "\"SN03\"\t750\r\n",
        "\"SN14\"\t2\r\n",
        "\"SN36\"\t5\r\n",
        "\"SN61\"\t22\r\n",
        "\"SN72\"\t9\r\n",
        "\"SN83\"\t9\r\n",
        "\"SX01\"\t570\r\n",
        "\"SX12\"\t416\r\n",
        "\"SX23\"\t27\r\n",
        "\"SX34\"\t12\r\n",
        "\"SX56\"\t2\r\n",
        "\"SX81\"\t9\r\n",
        "\"THIC\"\t452\r\n",
        "\"TMIN\"\t969579\r\n",
        "\"WDFG\"\t13759\r\n",
        "\"WDMV\"\t24052\r\n",
        "\"WT01\"\t239625\r\n",
        "\"WT09\"\t28469\r\n",
        "\"WT12\"\t84\r\n",
        "\"WV07\"\t63\r\n",
        "\"WV18\"\t15\r\n",
        "\"ACMH\"\t7960\r\n",
        "\"DWPR\"\t180462\r\n",
        "\"MDWM\"\t8429\r\n",
        "\"SN02\"\t3374\r\n",
        "\"SN13\"\t60\r\n",
        "\"SN35\"\t18\r\n",
        "\"SN82\"\t9\r\n",
        "\"SX11\"\t38\r\n",
        "\"SX22\"\t32\r\n",
        "\"SX33\"\t372\r\n",
        "\"SX55\"\t23\r\n",
        "\"WSFG\"\t14486\r\n",
        "\"WT08\"\t53648\r\n",
        "\"WT11\"\t120277\r\n",
        "\"WT19\"\t4631\r\n",
        "\"WT22\"\t5469\r\n",
        "\"WV20\"\t604\r\n",
        "\"header\"\t1\r\n",
        "\"AWND\"\t17950\r\n",
        "\"PSUN\"\t3322\r\n",
        "\"SN01\"\t571\r\n",
        "\"SN12\"\t416\r\n",
        "\"SN23\"\t27\r\n",
        "\"SN34\"\t11\r\n",
        "\"SN56\"\t2\r\n",
        "\"SN81\"\t9\r\n",
        "\"SX21\"\t29\r\n",
        "\"SX32\"\t2405\r\n",
        "\"SX54\"\t20\r\n",
        "\"TOBS\"\t478981\r\n",
        "\"WDF5\"\t13480\r\n",
        "\"WDFM\"\t3201\r\n",
        "\"WT07\"\t19440\r\n",
        "\"WT10\"\t2268\r\n",
        "\"WT18\"\t53072\r\n",
        "\"WT21\"\t2382\r\n",
        "\"DAWM\"\t8428\r\n",
        "\"MDTX\"\t6001\r\n",
        "\"SN11\"\t38\r\n",
        "\"SN22\"\t29\r\n",
        "\"SN33\"\t371\r\n",
        "\"SN55\"\t20\r\n",
        "\"SNOW\"\t881399\r\n",
        "\"SX17\"\t2\r\n",
        "\"SX31\"\t357\r\n",
        "\"SX53\"\t124\r\n",
        "\"WSF5\"\t13482\r\n",
        "\"WSFM\"\t3204\r\n",
        "\"WT06\"\t103479\r\n",
        "\"WT17\"\t6945\r\n",
        "\"ACSC\"\t14\r\n",
        "\"MDSF\"\t20365\r\n",
        "\"SN21\"\t28\r\n",
        "\"SN32\"\t2405\r\n",
        "\"SN54\"\t20\r\n",
        "\"SX52\"\t941\r\n",
        "\"WT05\"\t148289\r\n",
        "\"WT16\"\t73840\r\n",
        "\"WV03\"\t1540\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Two useful command-line utilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the mrjob command line depends on the same configuration file as the run-time library. This configuration file is, by default, located at ~/.mrjob.conf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mrjob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "usage: mrjob {subcommand|--help}\"\r\n",
        "\r\n",
        "subcommands:\r\n",
        "  audit-emr-usage:          Audit EMR usage\r\n",
        "  create-job-flow:          Create an EMR job flow\r\n",
        "  fetch-logs:               Fetch and parse EMR logs for errors and counters\r\n",
        "  report-long-jobs:         Report EMR jobs which have been running for a long time\r\n",
        "  run:                      Run a job\r\n",
        "  s3-tmpwatch:              Delete S3 keys older than a specified time\r\n",
        "  terminate-idle-job-flows: Terminate idle EMR job flows\r\n",
        "  terminate-job-flow:       Terminate a single EMR job flow\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mrjob audit-emr-usage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "getting job flow history...\r\n",
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-fcb2822bb960d782\r\n",
        "using s3://mrjob-fcb2822bb960d782/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling job flow stats...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\r\n",
        "  File \"/usr/local/bin/mrjob\", line 17, in <module>\r\n",
        "    main()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/cmd.py\", line 60, in main\r\n",
        "    commands[args[1]](args[2:])\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/cmd.py\", line 72, in audit_usage\r\n",
        "    main(args)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/tools/emr/audit_usage.py\", line 71, in main\r\n",
        "    stats = job_flows_to_stats(job_flows, now=now)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/tools/emr/audit_usage.py\", line 143, in job_flows_to_stats\r\n",
        "    for job_flow in job_flows]\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/tools/emr/audit_usage.py\", line 228, in job_flow_to_full_summary\r\n",
        "    jf['usage'] = job_flow_to_usage_data(job_flow, basic_summary=jf, now=now)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/tools/emr/audit_usage.py\", line 396, in job_flow_to_usage_data\r\n",
        "    step_start = to_datetime(step.startdatetime)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/tools/emr/audit_usage.py\", line 761, in to_datetime\r\n",
        "    return datetime.strptime(iso8601_time, boto.utils.ISO8601)\r\n",
        "  File \"/usr/lib/python2.7/_strptime.py\", line 325, in _strptime\r\n",
        "    (data_string, format))\r\n",
        "ValueError: time data '2014-05-20T19:55:01.389Z' does not match format '%Y-%m-%dT%H:%M:%SZ'\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "s3cmd is a utility that makes it easy to work with s3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!s3cmd --help"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: s3cmd [options] COMMAND [parameters]\r\n",
        "\r\n",
        "S3cmd is a tool for managing objects in Amazon S3 storage. It allows for\r\n",
        "making and removing \"buckets\" and uploading, downloading and removing\r\n",
        "\"objects\" from these buckets.\r\n",
        "\r\n",
        "Options:\r\n",
        "  -h, --help            show this help message and exit\r\n",
        "  --configure           Invoke interactive (re)configuration tool.\r\n",
        "  -c FILE, --config=FILE\r\n",
        "                        Config file name. Defaults to /home/ubuntu/.s3cfg\r\n",
        "  --dump-config         Dump current configuration after parsing config files\r\n",
        "                        and command line options and exit.\r\n",
        "  -n, --dry-run         Only show what should be uploaded or downloaded but\r\n",
        "                        don't actually do it. May still perform S3 requests to\r\n",
        "                        get bucket listings and other information though (only\r\n",
        "                        for file transfer commands)\r\n",
        "  -e, --encrypt         Encrypt files before uploading to S3.\r\n",
        "  --no-encrypt          Don't encrypt files.\r\n",
        "  -f, --force           Force overwrite and other dangerous operations.\r\n",
        "  --continue            Continue getting a partially downloaded file (only for\r\n",
        "                        [get] command).\r\n",
        "  --skip-existing       Skip over files that exist at the destination (only\r\n",
        "                        for [get] and [sync] commands).\r\n",
        "  -r, --recursive       Recursive upload, download or removal.\r\n",
        "  --check-md5           Check MD5 sums when comparing files for [sync].\r\n",
        "                        (default)\r\n",
        "  --no-check-md5        Do not check MD5 sums when comparing files for [sync].\r\n",
        "                        Only size will be compared. May significantly speed up\r\n",
        "                        transfer but may also miss some changed files.\r\n",
        "  -P, --acl-public      Store objects with ACL allowing read for anyone.\r\n",
        "  --acl-private         Store objects with default ACL allowing access for you\r\n",
        "                        only.\r\n",
        "  --acl-grant=PERMISSION:EMAIL or USER_CANONICAL_ID\r\n",
        "                        Grant stated permission to a given amazon user.\r\n",
        "                        Permission is one of: read, write, read_acp,\r\n",
        "                        write_acp, full_control, all\r\n",
        "  --acl-revoke=PERMISSION:USER_CANONICAL_ID\r\n",
        "                        Revoke stated permission for a given amazon user.\r\n",
        "                        Permission is one of: read, write, read_acp, wr\r\n",
        "                        ite_acp, full_control, all\r\n",
        "  --delete-removed      Delete remote objects with no corresponding local file\r\n",
        "                        [sync]\r\n",
        "  --no-delete-removed   Don't delete remote objects.\r\n",
        "  -p, --preserve        Preserve filesystem attributes (mode, ownership,\r\n",
        "                        timestamps). Default for [sync] command.\r\n",
        "  --no-preserve         Don't store FS attributes\r\n",
        "  --exclude=GLOB        Filenames and paths matching GLOB will be excluded\r\n",
        "                        from sync\r\n",
        "  --exclude-from=FILE   Read --exclude GLOBs from FILE\r\n",
        "  --rexclude=REGEXP     Filenames and paths matching REGEXP (regular\r\n",
        "                        expression) will be excluded from sync\r\n",
        "  --rexclude-from=FILE  Read --rexclude REGEXPs from FILE\r\n",
        "  --include=GLOB        Filenames and paths matching GLOB will be included\r\n",
        "                        even if previously excluded by one of\r\n",
        "                        --(r)exclude(-from) patterns\r\n",
        "  --include-from=FILE   Read --include GLOBs from FILE\r\n",
        "  --rinclude=REGEXP     Same as --include but uses REGEXP (regular expression)\r\n",
        "                        instead of GLOB\r\n",
        "  --rinclude-from=FILE  Read --rinclude REGEXPs from FILE\r\n",
        "  --bucket-location=BUCKET_LOCATION\r\n",
        "                        Datacentre to create bucket in. As of now the\r\n",
        "                        datacenters are: US (default), EU, us-west-1, and ap-\r\n",
        "                        southeast-1\r\n",
        "  --reduced-redundancy, --rr\r\n",
        "                        Store object with 'Reduced redundancy'. Lower per-GB\r\n",
        "                        price. [put, cp, mv]\r\n",
        "  --access-logging-target-prefix=LOG_TARGET_PREFIX\r\n",
        "                        Target prefix for access logs (S3 URI) (for [cfmodify]\r\n",
        "                        and [accesslog] commands)\r\n",
        "  --no-access-logging   Disable access logging (for [cfmodify] and [accesslog]\r\n",
        "                        commands)\r\n",
        "  -m MIME/TYPE, --mime-type=MIME/TYPE\r\n",
        "                        Default MIME-type to be set for objects stored.\r\n",
        "  -M, --guess-mime-type\r\n",
        "                        Guess MIME-type of files by their extension. Falls\r\n",
        "                        back to default MIME-Type as specified by --mime-type\r\n",
        "                        option\r\n",
        "  --add-header=NAME:VALUE\r\n",
        "                        Add a given HTTP header to the upload request. Can be\r\n",
        "                        used multiple times. For instance set 'Expires' or\r\n",
        "                        'Cache-Control' headers (or both) using this options\r\n",
        "                        if you like.\r\n",
        "  --encoding=ENCODING   Override autodetected terminal and filesystem encoding\r\n",
        "                        (character set). Autodetected: UTF-8\r\n",
        "  --verbatim            Use the S3 name as given on the command line. No pre-\r\n",
        "                        processing, encoding, etc. Use with caution!\r\n",
        "  --list-md5            Include MD5 sums in bucket listings (only for 'ls'\r\n",
        "                        command).\r\n",
        "  -H, --human-readable-sizes\r\n",
        "                        Print sizes in human readable form (eg 1kB instead of\r\n",
        "                        1234).\r\n",
        "  --progress            Display progress meter (default on TTY).\r\n",
        "  --no-progress         Don't display progress meter (default on non-TTY).\r\n",
        "  --enable              Enable given CloudFront distribution (only for\r\n",
        "                        [cfmodify] command)\r\n",
        "  --disable             Enable given CloudFront distribution (only for\r\n",
        "                        [cfmodify] command)\r\n",
        "  --cf-add-cname=CNAME  Add given CNAME to a CloudFront distribution (only for\r\n",
        "                        [cfcreate] and [cfmodify] commands)\r\n",
        "  --cf-remove-cname=CNAME\r\n",
        "                        Remove given CNAME from a CloudFront distribution\r\n",
        "                        (only for [cfmodify] command)\r\n",
        "  --cf-comment=COMMENT  Set COMMENT for a given CloudFront distribution (only\r\n",
        "                        for [cfcreate] and [cfmodify] commands)\r\n",
        "  --cf-default-root-object=DEFAULT_ROOT_OBJECT\r\n",
        "                        Set the default root object to return when no object\r\n",
        "                        is specified in the URL. Use a relative path, i.e.\r\n",
        "                        default/index.html instead of /default/index.html or\r\n",
        "                        s3://bucket/default/index.html (only for [cfcreate]\r\n",
        "                        and [cfmodify] commands)\r\n",
        "  -v, --verbose         Enable verbose output.\r\n",
        "  -d, --debug           Enable debug output.\r\n",
        "  --version             Show s3cmd version (1.0.0) and exit.\r\n",
        "  -F, --follow-symlinks\r\n",
        "                        Follow symbolic links as if they are regular files\r\n",
        "\r\n",
        "Commands:\r\n",
        "  Make bucket\r\n",
        "      s3cmd mb s3://BUCKET\r\n",
        "  Remove bucket\r\n",
        "      s3cmd rb s3://BUCKET\r\n",
        "  List objects or buckets\r\n",
        "      s3cmd ls [s3://BUCKET[/PREFIX]]\r\n",
        "  List all object in all buckets\r\n",
        "      s3cmd la \r\n",
        "  Put file into bucket\r\n",
        "      s3cmd put FILE [FILE...] s3://BUCKET[/PREFIX]\r\n",
        "  Get file from bucket\r\n",
        "      s3cmd get s3://BUCKET/OBJECT LOCAL_FILE\r\n",
        "  Delete file from bucket\r\n",
        "      s3cmd del s3://BUCKET/OBJECT\r\n",
        "  Synchronize a directory tree to S3\r\n",
        "      s3cmd sync LOCAL_DIR s3://BUCKET[/PREFIX] or s3://BUCKET[/PREFIX] LOCAL_DIR\r\n",
        "  Disk usage by buckets\r\n",
        "      s3cmd du [s3://BUCKET[/PREFIX]]\r\n",
        "  Get various information about Buckets or Files\r\n",
        "      s3cmd info s3://BUCKET[/OBJECT]\r\n",
        "  Copy object\r\n",
        "      s3cmd cp s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]\r\n",
        "  Move object\r\n",
        "      s3cmd mv s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]\r\n",
        "  Modify Access control list for Bucket or Files\r\n",
        "      s3cmd setacl s3://BUCKET[/OBJECT]\r\n",
        "  Enable/disable bucket access logging\r\n",
        "      s3cmd accesslog s3://BUCKET\r\n",
        "  Sign arbitrary string using the secret key\r\n",
        "      s3cmd sign STRING-TO-SIGN\r\n",
        "  Fix invalid file names in a bucket\r\n",
        "      s3cmd fixbucket s3://BUCKET[/PREFIX]\r\n",
        "  List CloudFront distribution points\r\n",
        "      s3cmd cflist \r\n",
        "  Display CloudFront distribution point parameters\r\n",
        "      s3cmd cfinfo [cf://DIST_ID]\r\n",
        "  Create CloudFront distribution point\r\n",
        "      s3cmd cfcreate s3://BUCKET\r\n",
        "  Delete CloudFront distribution point\r\n",
        "      s3cmd cfdelete cf://DIST_ID\r\n",
        "  Change CloudFront distribution point parameters\r\n",
        "      s3cmd cfmodify cf://DIST_ID\r\n",
        "\r\n",
        "For more informations see the progect homepage:\r\n",
        "http://s3tools.org\r\n",
        "\r\n",
        "Consider a donation if you have found s3cmd useful:\r\n",
        "http://s3tools.org/donate\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    }
   ],
   "metadata": {}
  }
 ]
}